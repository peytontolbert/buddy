Webserver IT ticket support system mixed with personal agent.
Use case for big business
Class HelpdeskAgent functions: add_to_conversation(appendmessage), generate_prompt(The following conversation is with a helpdesk AI. then add messages in conversation history after), escalate issue(logic to escalate issue such as sending email to human operator), answer_question(addmessagetoconvo, addprompt,getresponse)


useful reasoning steps:     

    def _reason(self) -> Union[str, Dict[Any, Any]]:
        current_task_description = self.task_manager.get_current_task_string()
        if current_task_description is None:
            return None
        else:  
            # Retrie task related memories
            with self.ui.loading("Retrieve memory..."):
                # Retrieve memories related to the task.
                related_past_episodes = self.episodic_memory.remember_related_episodes(
                    current_task_description,
                    k=3)
                if related_past_episodes is not None and len(related_past_episodes) > 0:
                    try:
                        self.ui.notify(title="TASK RELATED EPISODE",
                                    message=related_past_episodes)
                    except Exception as e:
                        print(e)
                # Retrieve concepts related to the task.
                if current_task_description is None:
                    return None
                else:
                    if len(current_task_description) > 0:
                        related_knowledge = self.semantic_memory.remember_related_knowledge(
                            current_task_description,
                            k=3
                        )
                        if related_knowledge is None:
                            related_knowledge = "No related knowledge."
                                                    # Get the relevant tools
                            # If agent has to much tools, use "remember_relevant_tools"
                            # because too many tool information will cause context windows overflow.
                            tools = self.procedural_memory.remember_all_tools()

                            # Set up the prompt
                            tool_info = ""
                            for tool in tools:
                                tool_info += tool.get_tool_info() + "\n"

                            # Get the recent episodes
                            memory = self.episodic_memory.remember_recent_episodes(2)

                            # If OpenAI Chat is available, it is used for higher accuracy results.
                            if current_task_description is not None and len(current_task_description) > 0:
                                propmt = ReasonPrompt.get_chat_template(
                                    memory=memory, 
                                    related_past_episodes=related_past_episodes,
                                    related_knowledge=related_knowledge,
                                    task=current_task_description,
                                    tool_info=tool_info
                                )
                                prompt = str(propmt)
                                results = openai.ChatCompletion.create(model="gpt-3.5-turbo-16k", messages=[{"role": "system", "content": prompt}])
                                result =  str(results['choices'][0]['message']['content'])

                            else:
                               return None
                            # Parse and validate the result
                            try:
                                result_json_obj = LLMJsonOutputParser.parse_and_validate(
                                    json_str=result,
                                    json_schema=REASON_JSON_SCHEMA_STR,
                                    gpt=self.gpt
                                )
                                return result_json_obj
                            except Exception as e:
                                raise Exception(f"Error: {e}")

                        else:
                            if len(related_knowledge) > 0:
                                self.ui.notify(title="TASK RELATED KNOWLEDGE",
                                    message=related_knowledge)
                            # Get the relevant tools
                            # If agent has to much tools, use "remember_relevant_tools"
                            # because too many tool information will cause context windows overflow.
                            tools = self.procedural_memory.remember_relevant_tools(current_task_description)

                            # Set up the prompt
                            tool_info = ""
                            for tool in tools:
                                tool_info += tool.get_tool_info() + "\n"

                            # Get the recent episodes
                            memory = self.episodic_memory.remember_recent_episodes(2)
                            Dicts = {"related_past_episodes":related_past_episodes,"related_knowledge":related_knowledge,"task":current_task_description,"tool_info":tool_info}
                            # If OpenAI Chat is available, it is used for higher accuracy results.
                            propmt = ReasonPrompt.get_templatechatgpt(
                                memory=memory, 
                                Dicts=Dicts
                            )
                            prompt = str(propmt)
                            memoryprompt = ReasonPrompt.memory_to_template(
                                memory=memory,
                            )
                            if memoryprompt is not None:
                                prompt += memoryprompt
                            schematemplate = ReasonPrompt.add_schema_template()
                            results = openai.ChatCompletion.create(model="gpt-3.5-turbo-16k", messages=[{"role": "system", "content": schematemplate},{"role": "user", "content": prompt}])
                            result = results['choices'][0]['message']['content']
                            try:
                                result_json_obj = LLMJsonOutputParser.parse_and_validate(
                                    json_str=result,
                                    json_schema=REASON_JSON_SCHEMA_STR
                                )
                                return result_json_obj
                            except Exception as e:
                                raise Exception(f"Error: {e}")
    def _act(self, tool_name: str, args: Dict) -> str:
        # Get the tool to use from the procedural memory
        try:
            tool = self.procedural_memory.remember_tool_by_name(tool_name)
        except Exception as e:
            return "Invalid command: " + str(e)
        try:
            result = tool.run(**args)
            return result
        except Exception as e:
            return "Could not run tool: " + str(e)